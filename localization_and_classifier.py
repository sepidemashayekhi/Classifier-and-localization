# -*- coding: utf-8 -*-
"""localization and classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yF8zpBEMoDgRFPuCmjot6mmkHOBEj9QY
"""

import tensorflow as tf 
from tensorflow import keras 
from keras.layers import Dense,Input,Conv2D,Flatten,BatchNormalization,Activation
from keras.layers import Dropout,Concatenate,MaxPooling2D,Add
from keras.models import Model

"""## creat model """

def inception_module(x,filters1_1,filters3_3_reduce,filters3_3,filters5_5_reduce,
                     filter5_5,filters_pool_proj,name=None):
  conv1x1=keras.layers.Conv2D(filters1_1,(1,1),padding='same',activation='relu')(x)
  per_conv3x3=keras.layers.Conv2D(filters3_3_reduce,(1,1),padding='same',activation='relu')(x)
  conv3x3=keras.layers.Conv2D(filters3_3,(3,3),padding='same',activation='relu')(per_conv3x3)
  per_conv5x5=keras.layers.Conv2D(filters5_5_reduce,(1,1),padding='same',activation='relu')(x)
  conv5x5=keras.layers.Conv2D(filter5_5,(5,5),padding='same',activation='relu')(per_conv5x5)
  pool_proj=keras.layers.MaxPool2D((3,3),strides=(1,1),padding='same')(x)
  pool_proj=keras.layers.Conv2D(filters_pool_proj,(1,1),padding='same',activation='relu')(pool_proj)
  
  output=keras.layers.concatenate([conv1x1,conv3x3,conv5x5,pool_proj],axis=3,name=name)

  return output

from keras import layers
input=Input(shape=(225,225,3))
# stage 1
layer=Conv2D(64,(7,7),padding='same')(input)
layer=BatchNormalization(axis=3)(layer)
layer=Activation('relu')(layer)
layer=MaxPooling2D(3,3)(layer)
 # stage 2
layer=inception_module(layer,64,96,128,16,32,32)
layer=MaxPooling2D((3,3))(layer)
layer=inception_module(layer,128,128,192,32,96,64)
layer=MaxPooling2D((3,3))(layer)
layer=inception_module(layer,128,128,192,32,96,64)
layer=Flatten()(layer)
# Classifier head 
clf_head=Dense(512,activation='relu')(layer)
clf_head=Dense(128,activation='relu')(clf_head)
clf_head=Dropout(rate=0.25)(clf_head)
clf_head=Dense(3,activation='softmax',name='class_label')(clf_head)
# Bbox head
bboxHead = Dense(128, activation="relu")(layer)
bboxHead = Dense(64, activation="relu")(bboxHead)
bboxHead = Dense(32, activation="relu")(bboxHead)
bboxHead = Dense(4, activation="sigmoid",name='bounding_box')(bboxHead)

model=Model(input,[clf_head,bboxHead])

losses = {
    "class_label": "categorical_crossentropy",
    "bounding_box": "mean_squared_error",
}
lossWeights = {
    "class_label": 1.0,
    "bounding_box": 1.0
}
model.compile(loss=losses, optimizer='adam', metrics=["accuracy"], loss_weights=lossWeights)

"""## Load Data"""

import os 
import numpy as np 
import pandas as pd
import matplotlib.pyplot as plt 
from keras.preprocessing.image import load_img,img_to_array
from cv2 import imread
from sklearn.preprocessing import LabelBinarizer

!unzip -d '/content/drive/MyDrive/dataset2'

annotationsPath='/content/drive/MyDrive/dataset2/annotations'
imagedir='/content/drive/MyDrive/dataset2/images'

bboxes=[]
labels=[]
images=[]

for csv in os.listdir(annotationsPath):
  csvpath=os.path.join(annotationsPath,csv)
  rows=open(csvpath).read().strip().split('\n')

  for row in rows:
    row = row.split(",")
    (filename, startX, startY, endX, endY, label) = row
    imagePath=os.path.join(imagedir,label,filename)
    image=load_img(imagePath)
    image=img_to_array(image)
    h,w=image.shape[:2]
    startX = float(startX) / w
    startY = float(startY) / h
    endX = float(endX) / w
    endY = float(endY) / h
    
    image=load_img(imagePath,target_size=(225,225,3))
    image=img_to_array(image)

    images.append(image)
    labels.append(label)
    bboxes.append((startX, startY, endX, endY))

images = np.array(images, dtype="float32") / 255.0
labels = np.array(labels)
bboxes = np.array(bboxes, dtype="float32")

lb = LabelBinarizer()
labels = lb.fit_transform(labels)

"""## Train model """

trainTargets = {
    "class_label": labels,
    "bounding_box": bboxes
}

model.fit(images,trainTargets,batch_size=32,validation_split=0.2,epochs=15)

model.save('my_model.h5')